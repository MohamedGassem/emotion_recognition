# emotion_recognition

The goal was to build a multimodal deep neural network for emotion detection using tf.keras. I had to work with the RAVDESS dataset, which contains short (~4 seconds long) video clip recordings of speakers, who are acting the different emotions through 2 sentences. After extracting and combine RGB frames with MFCCs, I had to utilize both video and audio information sources to achieve a better prediction.

This project was made for deep learning classes given in ELTE university in Budapest. Thanks to Kopácsi László and Fodor Ádám for their help.
